#!/usr/bin/env python3

import requests
import re
import sys
import time

sys.setrecursionlimit(100000)

num_climbs = 130
boulders = []
sports = []
trads = []
topropes = []

# Set up a session
s = requests.session()

# Get links from a html page
def get_links(content):
  links = re.findall('''<a\s+(?:[^>]*?\s+)?href="([^"]*)"''', content)  
  return links

# Get boulders from an HTML page
def get_climbs(content):
  info = re.findall('''@type.*\s*\"name\": \"([^\"]*).*\s*\"description\": \"([^\"]*)''',content)
  rating = re.findall('''&nbsp;Avg: (...)''',content)
  if len(rating) > 0 and len(info) > 0:
#    print(info)
    rating = rating[0]
    if rating[-1] == 'f':
      rating = rating[0]
    name = info[0][0]
    type = info[0][1]
    type = type.split(" ")
    grade = type[0]
    type = type[1]
    if type == 'Sport':
      type = 'sport'
      sports.append((grade,rating))
    elif type == 'Boulder':
      type = 'boulder'
      boulders.append((grade,rating))
    elif type == 'TR':
      type = 'toprope'
      topropes.append((grade,rating))
    elif 'Trad' in type:
      type = 'trad'
      trads.append((grade,rating))
    else:
      type = 'unk'
    print(name + " " + type + " " + grade + " " + rating + "/4 stars")

# Set of seen links
visited = set()

# Types of link we don't want to follow...
ignore = ['google','facebook','login','user','help','edit','share','upload','add','photo','forum','stats','print','map']

# Crawl a link
def crawl(url):
  #print("Crawling: " + url)
  if len(boulders) + len(sports) + len(trads) < num_climbs:
    response = s.get(url)
    if response == None:
      return

    page_content = response.content.decode('latin-1')
   
    # Get all links on the page
    links = get_links(page_content)

    # Add the climbs on the page
    get_climbs(page_content)

    # Remove links which we dont want to follow
    for word in ignore:
      links = [link for link in links if not word in link]

    # Only keep route and are links, this will get us all climbs
    links = [link for link in links if 'mountainproject' in link and ('area' in link or 'route' in link)]

    # Add the new links to our set so we don't visit them again
    for link in links:
      if not link in visited:
        visited.add(link)
        if len(visited) % 100 == 0:
          print("\n***\n" + str(len(visited)) + " pages searched... " + str(len(boulders)) + " boulders found... " + str(len(sports)) + " sport routes found... " + str(len(trads)) + " trad routes found... " + str(len(topropes)) + " toprope routes found... \n***\n")
        crawl(link)

# Start crawling!        
crawl('https://www.mountainproject.com')

# Sort and pint lists
boulders = sorted(boulders, key=lambda x: (x[0],x[1]))
sports = sorted(sports, key=lambda x: (x[0],x[1]))
trads = sorted(trads, key=lambda x: (x[0],x[1]))
topropes = sorted(topropes, key=lambda x: (x[0],x[1]))
print('CLIMBS: \n\n')

print('\n\nBOULDERS: ')
for boulder in boulders:
  print(boulder[0] + ", " + boulder[1])
print('\n\nSPORT ROUTES: ')
for sport in sports:
  print(sport[0] + ", " + sport[1])
print('\n\nTRAD ROUTES: ')
for trad in trads:
  print(trad[0] + ", " + trad[1])
print('\n\nTOPROPE ROUTES: ')
for toprope in topropes:
  print(toprope[0] + ", " + toprope[1])














